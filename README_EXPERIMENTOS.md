# ðŸ”¬ GuÃ­a de Experimentos - Transformer ASL Classification

## ðŸ“‹ Resumen de Modificaciones Implementadas

Este documento describe las modificaciones realizadas al proyecto para mejorar la organizaciÃ³n, trazabilidad y reproducibilidad de los experimentos de Machine Learning.

---

## âœ¨ CaracterÃ­sticas Implementadas

### 1. ðŸ§¹ Limpieza AutomÃ¡tica de Archivos Temporales
- Se eliminan automÃ¡ticamente las carpetas `output_videos/`, `temp_results/`, `old_results/` al inicio de cada ejecuciÃ³n
- Asegura ejecuciones limpias sin conflictos de archivos antiguos

### 2. ðŸ”§ ConfiguraciÃ³n DinÃ¡mica de Experimentos
Se agregÃ³ un sistema de configuraciÃ³n centralizado que permite cambiar fÃ¡cilmente entre tres estrategias experimentales:

#### **Experimento: Baseline**
```python
EXPERIMENT_TYPE = 'baseline'
```
- **Directorio de salida**: `./results/exp_baseline`
- **Class Weights**: No
- **Label Smoothing**: 0.0
- **Dropout**: 0.1
- **DescripciÃ³n**: Modelo base sin ajustes especiales

#### **Experimento: Class Weights**
```python
EXPERIMENT_TYPE = 'class_weights'
```
- **Directorio de salida**: `./results/exp_class_weights`
- **Class Weights**: SÃ­ (balanceo de clases)
- **Label Smoothing**: 0.0
- **Dropout**: 0.3
- **DescripciÃ³n**: Modelo con balanceo de clases por pesos

#### **Experimento: Label Smoothing**
```python
EXPERIMENT_TYPE = 'label_smoothing'
```
- **Directorio de salida**: `./results/exp_label_smoothing`
- **Class Weights**: No
- **Label Smoothing**: 0.1
- **Dropout**: 0.3
- **DescripciÃ³n**: Modelo usando Label Smoothing

### 3. ðŸ“Š Visualizaciones con Etiquetas Legibles

**ANTES** (âŒ ProblemÃ¡tico):
- Matrices de confusiÃ³n con Ã­ndices numÃ©ricos (0, 1, 2, 3...)
- Imposible saber quÃ© gesto representa cada nÃºmero
- DifÃ­cil interpretaciÃ³n de resultados

**DESPUÃ‰S** (âœ… Mejorado):
- Todas las visualizaciones usan nombres reales de gestos
- Matriz de confusiÃ³n legible con etiquetas en ambos ejes
- AnÃ¡lisis por clase con nombres descriptivos
- Colores diferenciados segÃºn rendimiento

### 4. ðŸ“ Artefactos Generados por Experimento

Cada experimento genera automÃ¡ticamente estos archivos en su directorio correspondiente:

#### **config.json**
Archivo JSON con todos los hiperparÃ¡metros y configuraciÃ³n del experimento:
```json
{
  "experiment_type": "baseline",
  "architecture": "TransformerEncoderOnly",
  "dropout": 0.1,
  "label_smoothing": 0.0,
  "use_class_weights": false,
  "test_accuracy": 0.9138,
  "test_macro_f1": 0.8736,
  "test_top3_accuracy": 0.9943,
  ...
}
```

#### **metrics.csv**
Formato estricto `Metric,Value` con mÃ©tricas principales:
```csv
Metric,Value
Accuracy,0.9137931034482759
Macro-F1,0.8735598342661747
Top-3 Accuracy,0.9942528735632183
Test Loss,0.9224783046679064
```

#### **training_log.csv**
Historial completo del entrenamiento por Ã©poca:
```csv
epoch,train_loss,train_acc,val_loss,val_acc,lr
0,2.5432,0.3456,2.1234,0.4123,0.0001
1,1.9876,0.5234,1.7654,0.5789,0.00009
...
```

#### **confusion_matrix.csv**
Matriz de confusiÃ³n en formato CSV (valores numÃ©ricos)

#### **confusion_matrix.png**
VisualizaciÃ³n de alta calidad (300 DPI) con:
- Nombres de clases en ejes X e Y
- Heatmap con valores anotados
- Colores profesionales
- TamaÃ±o optimizado para publicaciones (20x18 inches)

#### **training_curves.png**
GrÃ¡ficos de curvas de aprendizaje que incluyen:
- Loss de entrenamiento vs validaciÃ³n
- Accuracy de entrenamiento vs validaciÃ³n
- ProgramaciÃ³n del Learning Rate
- MÃ©tricas finales en Test Set
- Marca visual del mejor epoch

#### **per_class_analysis.png**
AnÃ¡lisis detallado por cada gesto con 3 grÃ¡ficos:
- **Precision por clase**: QuÃ© tan exacto es el modelo para cada gesto
- **Recall por clase**: QuÃ© tan completo es el modelo (sensibilidad)
- **F1-Score por clase**: Balance entre precision y recall
- CÃ³digo de colores: Verde (>0.7), Naranja (0.5-0.7), Rojo (<0.5)

#### **per_class_metrics.csv**
Tabla detallada con mÃ©tricas individuales para cada clase

#### **best_model.pt**
Pesos del modelo correspondientes al mejor epoch de validaciÃ³n

---

## ðŸš€ CÃ³mo Usar el Notebook Modificado

### Paso 1: Seleccionar Experimento
Edita la variable en la celda de configuraciÃ³n:
```python
EXPERIMENT_TYPE = 'baseline'  # Cambiar a: 'class_weights' o 'label_smoothing'
```

### Paso 2: Ejecutar Todo el Notebook
- Ejecuta todas las celdas secuencialmente
- El sistema automÃ¡ticamente:
  - Limpia archivos temporales
  - Crea directorios de salida
  - Configura hiperparÃ¡metros
  - Entrena el modelo
  - Genera todas las visualizaciones
  - Guarda todos los artefactos

### Paso 3: Revisar Resultados
Navega a la carpeta correspondiente en `results/exp_[nombre]/` para encontrar todos los artefactos generados.

---

## ðŸ“‚ Estructura de Directorios Final

```
transformer-asl-classification/
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ exp_baseline/
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”œâ”€â”€ metrics.csv
â”‚   â”‚   â”œâ”€â”€ training_log.csv
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.csv
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”‚   â”œâ”€â”€ per_class_analysis.png
â”‚   â”‚   â”œâ”€â”€ per_class_metrics.csv
â”‚   â”‚   â””â”€â”€ best_model.pt
â”‚   â”‚
â”‚   â”œâ”€â”€ exp_class_weights/
â”‚   â”‚   â””â”€â”€ [mismos archivos]
â”‚   â”‚
â”‚   â””â”€â”€ exp_label_smoothing/
â”‚       â””â”€â”€ [mismos archivos]
â”‚
â”œâ”€â”€ embedding_frame_gcn/          # (Reorganizado desde G4-EMBEDDING FRAME A FRAME GCN)
â”‚   â”œâ”€â”€ results_baseline/
â”‚   â”œâ”€â”€ results_class_weights/
â”‚   â””â”€â”€ results_label_smoothing/
â”‚
â”œâ”€â”€ embedding_frame_umap/         # (Reorganizado desde G4-EMBEDDING FRAME A FRAME UMAP)
â”‚   â”œâ”€â”€ results_baseline/
â”‚   â”œâ”€â”€ results_class_weights/
â”‚   â””â”€â”€ results_label_smoothing/
â”‚
â”œâ”€â”€ json_normalized/               # (Reorganizado desde G4-JSON-NORM)
â”‚   â”œâ”€â”€ results_baseline/
â”‚   â”œâ”€â”€ results_class_weights/
â”‚   â””â”€â”€ results_label_smoothing/
â”‚
â”œâ”€â”€ Experimento.ipynb             # âš¡ Notebook principal (MODIFICADO)
â”œâ”€â”€ reorganize_and_visualize.py   # ðŸ†• Script de reorganizaciÃ³n
â””â”€â”€ README_EXPERIMENTOS.md        # ðŸ†• Esta guÃ­a
```

---

## ðŸ“Š ComparaciÃ³n de Experimentos

Una vez ejecutados los tres experimentos, puedes comparar fÃ¡cilmente los resultados:

| MÃ©trica | Baseline | Class Weights | Label Smoothing |
|---------|----------|---------------|-----------------|
| Accuracy | ? | ? | ? |
| Macro-F1 | ? | ? | ? |
| Top-3 Accuracy | ? | ? | ? |
| Test Loss | ? | ? | ? |

*(Completar despuÃ©s de ejecutar los experimentos)*

---

## ðŸ” Mejoras Clave

### âœ… Antes vs DespuÃ©s

| Aspecto | Antes | DespuÃ©s |
|---------|-------|---------|
| **OrganizaciÃ³n** | Carpetas con nombres inconsistentes (G4, G5, g8.0...) | Nomenclatura clara y jerÃ¡rquica |
| **Visualizaciones** | Ãndices numÃ©ricos (0, 1, 2...) | Nombres reales de gestos |
| **ConfiguraciÃ³n** | Hard-coded en mÃºltiples lugares | Centralizada y dinÃ¡mica |
| **Reproducibilidad** | DifÃ­cil cambiar entre experimentos | Un solo cambio de variable |
| **Formato de MÃ©tricas** | Inconsistente | Formato estÃ¡ndar Metric,Value |
| **DocumentaciÃ³n** | MÃ­nima o ausente | Config.json completo por experimento |

---

## ðŸ’¡ Consejos para Mejores Resultados

1. **Ejecuta experimentos en orden**: Baseline â†’ Class Weights â†’ Label Smoothing
2. **Guarda checkpoints frecuentemente**: El early stopping ya lo hace automÃ¡ticamente
3. **Compara resultados visuales**: Las imÃ¡genes PNG son mÃ¡s fÃ¡ciles de interpretar que los CSV
4. **Revisa el anÃ¡lisis por clase**: Identifica quÃ© gestos necesitan mÃ¡s datos o mejoras
5. **Documenta cambios**: Si modificas hiperparÃ¡metros manualmente, anÃ³talos en config.json

---

## ðŸ› ï¸ Herramientas Adicionales

### Script de ReorganizaciÃ³n
El archivo `reorganize_and_visualize.py` puede usarse para reorganizar experimentos antiguos:

```bash
python reorganize_and_visualize.py
```

Este script:
- Carga nombres de clases desde `daataset/frame to frame/class_names.npy`
- Reorganiza carpetas antiguas (G4, G5, etc.)
- Genera visualizaciones con nombres de clases
- Crea reportes comparativos

---

## ðŸ“ž Soporte

Si encuentras problemas o necesitas modificar la configuraciÃ³n:

1. Revisa que `class_names` estÃ© correctamente cargado
2. Verifica que las rutas de archivos sean correctas
3. AsegÃºrate de tener instaladas todas las dependencias: `pandas`, `matplotlib`, `seaborn`, `sklearn`, `torch`

---

## ðŸ“ Changelog

### v2.0 - 2026-01-26
- âœ… Agregada limpieza automÃ¡tica de archivos temporales
- âœ… Implementado sistema de configuraciÃ³n dinÃ¡mica
- âœ… Visualizaciones con nombres reales de clases
- âœ… GeneraciÃ³n automÃ¡tica de todos los artefactos
- âœ… Formato estandarizado de mÃ©tricas (Metric,Value)
- âœ… InclusiÃ³n de Top-3 Accuracy
- âœ… AnÃ¡lisis detallado por clase con nombres
- âœ… DocumentaciÃ³n completa
- âœ… ReestructuraciÃ³n de directorios con nomenclatura consistente

---

**Autor**: MLOps Engineer  
**Fecha**: 26 de Enero, 2026  
**VersiÃ³n**: 2.0
