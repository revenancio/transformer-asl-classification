
================================================================================
RESUMEN EJECUTIVO - TRANSFORMER ENCODER-ONLY (G4)
================================================================================

üìä PERFORMANCE:
  ‚Ä¢ Test Accuracy:       0.7529
  ‚Ä¢ Macro F1-Score:      0.6598
  ‚Ä¢ Top-3 Accuracy:      0.8851
  ‚Ä¢ Test Loss:           1.2458

üèóÔ∏è ARQUITECTURA:
  ‚Ä¢ Modelo:              Transformer Encoder-Only (NO decoder)
  ‚Ä¢ Input Features:      228 (hand + pose + face features)
  ‚Ä¢ Sequence Length:     96 frames
  ‚Ä¢ Embedding Dim:       256
  ‚Ä¢ Attention Heads:     4
  ‚Ä¢ Encoder Layers:      4
  ‚Ä¢ Total Parameters:    2,228,382
  ‚Ä¢ Trainable Params:    2,228,382

‚öôÔ∏è ENTRENAMIENTO:
  ‚Ä¢ Optimizer:           AdamW (lr=1e-4, weight_decay=1e-4)
  ‚Ä¢ Loss Function:       CrossEntropyLoss (label_smoothing=0.0)
  ‚Ä¢ Batch Size:          8 (GPU: GTX 1660 Super 6GB)
  ‚Ä¢ Epochs Totales:      50
  ‚Ä¢ Best Epoch:          50 (Val Acc: 0.7914)
  ‚Ä¢ Early Stopping:      S√≠ (patience=8)
  ‚Ä¢ Gradient Clipping:   max_norm=1.0
  ‚Ä¢ Experimento:         BASELINE
  ‚Ä¢ Class Weights:       No

üéØ CARACTER√çSTICAS CLAVE:
  1. ‚úì Proyecci√≥n inicial: 228 ‚Üí 256
  2. ‚úì Positional Encoding aprendible (no sinusoidal)
  3. ‚úì Masked Multi-Head Attention (src_key_padding_mask)
  4. ‚úì Activaci√≥n GELU en feedforward
  5. ‚úì Masked mean pooling para representaci√≥n global
  6. ‚úì Clasificador MLP con dropout (0.1)
  7. ‚úì Label smoothing (Œµ=0.0) para regularizaci√≥n

üìà JUSTIFICACI√ìN ACAD√âMICA:
  ‚Ä¢ Encoder-only: Adecuado porque la tarea es clasificaci√≥n global, NO secuencia-a-secuencia
  ‚Ä¢ Sin decoder: No hay generaci√≥n, no hay necesidad de autoregresi√≥n
  ‚Ä¢ Masked attention: Respeta padding frames (no 96 frames reales en todos los videos)
  ‚Ä¢ Mean pooling: Agregaci√≥n temporal efectiva para tomar decisi√≥n global
  ‚Ä¢ Positional encoding aprendible: Mejor adaptaci√≥n a distribuci√≥n temporal de features
  ‚Ä¢ Label smoothing: Reduce overfitting en dataset de 868 muestras
  ‚Ä¢ Early stopping: Previene overfitting y optimiza tiempo de c√≥mputo

üíæ OUTPUTS GENERADOS (FORMATO G4):
  ‚úì best_model.pt                 - Pesos del mejor modelo
  ‚úì config.json                   - Configuraci√≥n completa
  ‚úì metrics.csv                   - M√©tricas principales (Metric,Value)
  ‚úì per_class_metrics.csv         - M√©tricas por clase
  ‚úì confusion_matrix.csv          - Matriz de confusi√≥n
  ‚úì training_log.csv              - Log de entrenamiento
  ‚úì training_curves.png           - Gr√°ficos de loss/accuracy
  ‚úì confusion_matrix.png          - Visualizaci√≥n matriz confusi√≥n
  ‚úì per_class_analysis.png        - An√°lisis por clase

üìÅ CARPETA DE SALIDA: C:\Users\Los milluelitos repo\Desktop\experimento tesis\transformer-asl-classification\G4-JSON-NORM\G4-RESULTS

================================================================================
